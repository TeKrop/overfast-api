name: "Sync Upstream & Deploy"

permissions:
  contents: write

on:
  # schedule:
  #   # Run daily at 6:00 UTC
  #   - cron: "0 6 * * *"
  workflow_dispatch:
    inputs:
      force_deploy:
        description: "Force deployment even if no updates"
        required: false
        default: false
        type: boolean

jobs:
  # ── Stage 1: Merge upstream locally (do NOT push) ──────────────
  merge-staging:
    name: Merge upstream (staging)
    runs-on: ubuntu-latest
    outputs:
      has_updates: ${{ steps.check.outputs.has_updates }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Configure git
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

      - name: Configure merge drivers
        run: |
          # "accept-upstream" driver: replaces our file with upstream's version
          git config merge.accept-upstream.name "Accept upstream version"
          git config merge.accept-upstream.driver "cp '%B' '%A'"

          # "keep-fork" driver: keeps our fork version unchanged
          git config merge.keep-fork.name "Keep fork version"
          git config merge.keep-fork.driver true

      - name: Add upstream remote and fetch
        run: |
          git remote add upstream https://github.com/TeKrop/overfast-api.git || true
          git fetch upstream

      - name: Check for upstream updates
        id: check
        run: |
          set -euo pipefail
          NEW_COMMITS=$(git log HEAD..upstream/main --oneline)

          if [ -n "$NEW_COMMITS" ]; then
            echo "New upstream commits found:"
            echo "$NEW_COMMITS"
            echo "has_updates=true" >> $GITHUB_OUTPUT
          else
            echo "No new commits from upstream"
            echo "has_updates=false" >> $GITHUB_OUTPUT
          fi

      - name: Merge upstream locally
        if: steps.check.outputs.has_updates == 'true'
        run: |
          git merge upstream/main -m "chore: merge upstream changes"
          echo "Merge successful — commit not pushed yet"

      - name: Archive merged repository
        if: steps.check.outputs.has_updates == 'true'
        run: tar czf /tmp/merged-repo.tar.gz .

      - name: Upload merged repo artifact
        if: steps.check.outputs.has_updates == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: merged-repo
          path: /tmp/merged-repo.tar.gz
          retention-days: 1

  # ── Stage 2a: Lint & test (parallel with smoke-test) ───────────
  ci-checks:
    name: CI checks (ruff, ty, pytest)
    needs: merge-staging
    if: needs.merge-staging.outputs.has_updates == 'true' || github.event.inputs.force_deploy == 'true'
    runs-on: ubuntu-latest

    steps:
      - name: Download merged repo
        if: needs.merge-staging.outputs.has_updates == 'true'
        uses: actions/download-artifact@v4
        with:
          name: merged-repo

      - name: Extract archive
        if: needs.merge-staging.outputs.has_updates == 'true'
        run: tar xzf merged-repo.tar.gz && rm merged-repo.tar.gz

      - name: Checkout current main
        if: needs.merge-staging.outputs.has_updates != 'true'
        uses: actions/checkout@v4

      - name: Set up uv
        uses: astral-sh/setup-uv@v3
        with:
          version: "0.9.28"

      - name: Set up Python
        run: uv python install 3.14

      - name: Install the project
        run: uv sync --frozen --no-cache

      - name: Run ruff code analysis
        run: uv run ruff check .

      - name: Run ty code analysis
        run: uv run ty check .

      - name: Run test suite
        run: |
          PYTHONPATH=app/ uv run python -m pytest -v --cov-fail-under=80 --cov-report=term-missing --cov=app/ tests/

  # ── Stage 2b: Docker smoke test (parallel with ci-checks) ─────
  smoke-test:
    name: Smoke test (Docker)
    needs: merge-staging
    if: needs.merge-staging.outputs.has_updates == 'true' || github.event.inputs.force_deploy == 'true'
    runs-on: ubuntu-latest

    steps:
      - name: Download merged repo
        if: needs.merge-staging.outputs.has_updates == 'true'
        uses: actions/download-artifact@v4
        with:
          name: merged-repo

      - name: Extract archive
        if: needs.merge-staging.outputs.has_updates == 'true'
        run: tar xzf merged-repo.tar.gz && rm merged-repo.tar.gz

      - name: Checkout current main
        if: needs.merge-staging.outputs.has_updates != 'true'
        uses: actions/checkout@v4

      - name: Create .env from defaults
        run: |
          cp .env.dist .env
          sed -i 's/^APP_PORT=.*/APP_PORT=8080/' .env

      - name: Build and start services
        run: |
          docker compose build
          docker compose up -d

      - name: Wait for services to be healthy
        run: |
          echo "Waiting for core services (app, nginx, valkey) to become healthy..."
          SERVICES="app nginx valkey"
          TIMEOUT=150
          INTERVAL=5

          for i in $(seq 1 $((TIMEOUT / INTERVAL))); do
            HEALTHY=0
            for SERVICE in $SERVICES; do
              STATUS=$(docker compose ps --format json | jq -rs \
                "[.[] | select(.Service == \"$SERVICE\")] | .[0].Health // \"starting\"")
              if [ "$STATUS" = "healthy" ]; then
                HEALTHY=$((HEALTHY + 1))
              fi
            done

            ELAPSED=$((i * INTERVAL))
            echo "[$ELAPSED/${TIMEOUT}s] $HEALTHY/3 services healthy"

            if [ "$HEALTHY" -eq 3 ]; then
              echo "All core services are healthy!"
              exit 0
            fi

            sleep $INTERVAL
          done

          echo "ERROR: Timed out waiting for services to become healthy"
          docker compose ps
          docker compose logs
          exit 1

      - name: Validate API endpoints
        run: |
          set -euo pipefail
          BASE_URL="http://localhost:8080"
          ERRORS=0

          fetch() {
            curl -sf --compressed "$BASE_URL$1"
          }

          fail() {
            echo "  FAIL: $1"
            ERRORS=$((ERRORS + 1))
          }

          # ── GET / → HTML docs page ──
          echo "=== GET / ==="
          BODY=$(fetch "/") || { fail "/ not reachable"; ERRORS=$((ERRORS+1)); }
          echo "$BODY" | grep -q "redoc" || fail "/ does not contain redoc HTML"
          echo "  OK"

          # ── GET /openapi.json → valid OpenAPI spec ──
          echo "=== GET /openapi.json ==="
          BODY=$(fetch "/openapi.json") || { fail "/openapi.json not reachable"; ERRORS=$((ERRORS+1)); }
          echo "$BODY" | jq -e '.openapi' > /dev/null || fail "missing openapi version field"
          echo "$BODY" | jq -e '.paths | keys | length > 5' > /dev/null || fail "too few paths in spec"
          echo "  OK"

          # ── GET /roles → exactly 3 roles with required fields ──
          echo "=== GET /roles ==="
          BODY=$(fetch "/roles") || { fail "/roles not reachable"; ERRORS=$((ERRORS+1)); }
          COUNT=$(echo "$BODY" | jq 'length')
          [ "$COUNT" -eq 3 ] || fail "expected 3 roles, got $COUNT"
          KEYS=$(echo "$BODY" | jq -r '.[].key' | sort | tr '\n' ',')
          [ "$KEYS" = "damage,support,tank," ] || fail "role keys mismatch: $KEYS"
          echo "$BODY" | jq -e 'all(has("key","name","icon","description"))' > /dev/null \
            || fail "roles missing required fields"
          echo "$BODY" | jq -e 'all(.icon | startswith("http"))' > /dev/null \
            || fail "role icons are not valid URLs"
          echo "  OK: $COUNT roles (damage, support, tank)"

          # ── GET /gamemodes → 10+ gamemodes with data ──
          echo "=== GET /gamemodes ==="
          BODY=$(fetch "/gamemodes") || { fail "/gamemodes not reachable"; ERRORS=$((ERRORS+1)); }
          COUNT=$(echo "$BODY" | jq 'length')
          [ "$COUNT" -ge 10 ] || fail "expected ≥10 gamemodes, got $COUNT"
          echo "$BODY" | jq -e 'all(has("key","name","icon","description","screenshot"))' > /dev/null \
            || fail "gamemodes missing required fields"
          echo "$BODY" | jq -e 'all(.description | length > 10)' > /dev/null \
            || fail "gamemode descriptions too short or empty"
          # Spot-check known gamemodes
          echo "$BODY" | jq -e 'map(.key) | contains(["control","escort","push"])' > /dev/null \
            || fail "known gamemodes (control, escort, push) not found"
          echo "  OK: $COUNT gamemodes"

          # ── GET /maps → 40+ maps with structure ──
          echo "=== GET /maps ==="
          BODY=$(fetch "/maps") || { fail "/maps not reachable"; ERRORS=$((ERRORS+1)); }
          COUNT=$(echo "$BODY" | jq 'length')
          [ "$COUNT" -ge 40 ] || fail "expected ≥40 maps, got $COUNT"
          echo "$BODY" | jq -e 'all(has("key","name","screenshot","gamemodes","location"))' > /dev/null \
            || fail "maps missing required fields"
          echo "$BODY" | jq -e 'all(.gamemodes | length >= 1)' > /dev/null \
            || fail "some maps have no gamemodes"
          echo "$BODY" | jq -e 'all(.screenshot | startswith("http"))' > /dev/null \
            || fail "map screenshots are not valid URLs"
          # Spot-check known maps
          echo "$BODY" | jq -e 'map(.key) | contains(["ilios","dorado","kings-row"])' > /dev/null \
            || fail "known maps (ilios, dorado, kings-row) not found"
          echo "  OK: $COUNT maps"

          # ── GET /heroes → 40+ heroes with structure ──
          echo "=== GET /heroes ==="
          BODY=$(fetch "/heroes") || { fail "/heroes not reachable"; ERRORS=$((ERRORS+1)); }
          COUNT=$(echo "$BODY" | jq 'length')
          [ "$COUNT" -ge 40 ] || fail "expected ≥40 heroes, got $COUNT"
          echo "$BODY" | jq -e 'all(has("key","name","portrait","role"))' > /dev/null \
            || fail "heroes missing required fields"
          echo "$BODY" | jq -e 'all(.role | IN("damage","support","tank"))' > /dev/null \
            || fail "heroes have invalid roles"
          echo "$BODY" | jq -e 'all(.portrait | startswith("http"))' > /dev/null \
            || fail "hero portraits are not valid URLs"
          # Spot-check known heroes
          echo "$BODY" | jq -e 'map(.key) | contains(["ana","tracer","reinhardt"])' > /dev/null \
            || fail "known heroes (ana, tracer, reinhardt) not found"
          # Verify role distribution (should have heroes in each role)
          for ROLE in damage support tank; do
            ROLE_COUNT=$(echo "$BODY" | jq "[.[] | select(.role == \"$ROLE\")] | length")
            [ "$ROLE_COUNT" -ge 5 ] || fail "only $ROLE_COUNT $ROLE heroes (expected ≥5)"
          done
          echo "  OK: $COUNT heroes"

          # ── Summary ──
          echo ""
          if [ "$ERRORS" -gt 0 ]; then
            echo "FAILED: $ERRORS validation error(s)"
            exit 1
          fi
          echo "All endpoint validations passed!"

      - name: Dump logs on failure
        if: failure()
        run: docker compose logs --tail=200

  # ── Stage 3: Push validated merge to main ──────────────────────
  commit-to-main:
    name: Push to main
    needs: [merge-staging, ci-checks, smoke-test]
    if: needs.merge-staging.outputs.has_updates == 'true'
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Configure git
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

      - name: Configure merge drivers
        run: |
          git config merge.accept-upstream.name "Accept upstream version"
          git config merge.accept-upstream.driver "cp '%B' '%A'"
          git config merge.keep-fork.name "Keep fork version"
          git config merge.keep-fork.driver true

      - name: Merge upstream and push
        run: |
          git remote add upstream https://github.com/TeKrop/overfast-api.git || true
          git fetch upstream
          git fetch origin
          git reset --hard origin/main
          git merge upstream/main -m "chore: merge upstream changes"
          git push origin main
          echo "Merge commit pushed to main successfully"

  # ── Stage 4: Deploy (requires manual approval) ─────────────────
  deploy:
    name: Deploy to VPS
    needs: [merge-staging, ci-checks, smoke-test, commit-to-main]
    if: always() && (needs.commit-to-main.result == 'success' || (github.event.inputs.force_deploy == 'true' && needs.smoke-test.result == 'success'))
    runs-on: ubuntu-latest
    environment: production

    steps:
      - name: Deploy via SSH
        uses: appleboy/ssh-action@v1
        with:
          host: ${{ secrets.VPS_HOST }}
          port: ${{ secrets.VPS_PORT }}
          username: ${{ secrets.VPS_USER }}
          key: ${{ secrets.VPS_SSH_KEY }}
          script: |
            /opt/deploy-overfast.sh

